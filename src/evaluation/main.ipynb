{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import math\n",
    "import dotenv\n",
    "\n",
    "from typing import List, Dict, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dotenv.dotenv_values()\n",
    "\n",
    "Part = Literal[\"sentence\", \"paragraph\", \"page\"]\n",
    "Language = Literal[\"en\", \"sk\", \"de\"]\n",
    "Model = Literal[\"e5\", \"labse\", \"gte\"]\n",
    "Id = str\n",
    "\n",
    "PARTS: List[Part] = [\"paragraph\", \"sentence\", \"page\"][:1]\n",
    "LANGUAGES: List[Language] = [\"en\", \"sk\", \"de\"]\n",
    "MODELS: List[Model] = [\"e5\", \"labse\", \"gte\"]\n",
    "PG_TGRM = \"tgrm\"\n",
    "CHAT_GPT = \"chat-gpt\"\n",
    "\n",
    "ALL_MODELS = [PG_TGRM, *MODELS]\n",
    "\n",
    "DATA_DIR = \"../../data\"\n",
    "\n",
    "SPACE = \" \"\n",
    "\n",
    "\n",
    "ALL_RETRIEVAL_MODELS = [PG_TGRM, *MODELS, CHAT_GPT]\n",
    "MODEL_COMBINATIONS = []\n",
    "for idx in range(len(ALL_RETRIEVAL_MODELS)):\n",
    "    for j in range(idx + 1, len(ALL_RETRIEVAL_MODELS)):\n",
    "        m1 = ALL_RETRIEVAL_MODELS[idx]\n",
    "        m2 = ALL_RETRIEVAL_MODELS[j]\n",
    "        MODEL_COMBINATIONS.append((m1, m2))\n",
    "\n",
    "\n",
    "with open(f\"{DATA_DIR}/dataset/02_queries-EN.json\", \"r\") as file:\n",
    "    en_queries: List[str] = json.load(file)\n",
    "with open(f\"{DATA_DIR}/dataset/02_queries-SK.json\", \"r\") as file:\n",
    "    sk_queries: List[str] = json.load(file)\n",
    "with open(f\"{DATA_DIR}/dataset/02_queries-DE.json\", \"r\") as file:\n",
    "    de_queries: List[str] = json.load(file)\n",
    "\n",
    "queries_by_language = {\n",
    "    \"en\": en_queries,\n",
    "    \"sk\": sk_queries,\n",
    "    \"de\": de_queries\n",
    "}\n",
    "\n",
    "COEFFS = [0.05, 0.10, 0.20, 0.25, 0.30, 1.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_attr(object: dict, path: str, value, *, append: bool = False):\n",
    "    keys = path.split(\".\")\n",
    "    last_key = keys[-1]\n",
    "\n",
    "    for key in keys[:-1]:\n",
    "        if key not in object:\n",
    "            object[key] = {}\n",
    "\n",
    "        object = object[key]\n",
    "\n",
    "    if last_key in object:\n",
    "        if append:\n",
    "            object[last_key].append(value)\n",
    "        else:\n",
    "            object[last_key] = value\n",
    "    else:\n",
    "        if append:\n",
    "            object[last_key] = [value]\n",
    "        else:\n",
    "            object[last_key] = value\n",
    "\n",
    "\n",
    "def get_attr(object: dict, path: str):\n",
    "    keys = path.split(\".\")\n",
    "    last_key = keys[-1]\n",
    "\n",
    "    for key in keys[:-1]:\n",
    "        if key not in object:\n",
    "            return None\n",
    "\n",
    "        object = object[key]\n",
    "\n",
    "    if last_key not in object:\n",
    "        return None\n",
    "\n",
    "    return object[last_key]\n",
    "\n",
    "\n",
    "def plm():\n",
    "    result = []\n",
    "\n",
    "    for part in PARTS:\n",
    "        for lang in LANGUAGES:\n",
    "            for model in ALL_MODELS:\n",
    "                result.append((part, lang, model))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def plmi():\n",
    "    result = []\n",
    "\n",
    "    for part, lang, model in plm():\n",
    "        for idx in range(len(queries_by_language[lang])):\n",
    "            result.append((part, lang, model, idx))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_id(part: Part, lang: Language, idx: int) -> Id:\n",
    "    return f\"{part}-{lang}-{idx + 1}\"\n",
    "\n",
    "\n",
    "def get_retrieval_path(model: Model, id: Id):\n",
    "    return f\"{DATA_DIR}/retrieval/{model}/{id}.json\"\n",
    "\n",
    "\n",
    "def normalize(maxx, minn, similarity):\n",
    "    return (similarity - minn) / (maxx - minn)\n",
    "\n",
    "\n",
    "def get_top_docs(docs, coeff: float):\n",
    "    if len(docs) == 0:\n",
    "        return []\n",
    "\n",
    "    top_doc = docs[0]\n",
    "    top_similarity = top_doc[\"similarity\"]\n",
    "    similarity_threshold = top_similarity * (1 - coeff)\n",
    "\n",
    "    return list(filter(\n",
    "        lambda doc: doc[\"similarity\"] >= similarity_threshold,\n",
    "        docs\n",
    "    ))\n",
    "\n",
    "\n",
    "def get_ordering_score(docs_1, docs_2):\n",
    "    match_count = 0\n",
    "\n",
    "    l1 = len(docs_1)\n",
    "    l2 = len(docs_2)\n",
    "\n",
    "    if min(l1, l2) == 0:\n",
    "        return 0\n",
    "\n",
    "    for i in range(min(l1, l2)):\n",
    "        doc_1 = docs_1[i]\n",
    "        doc_2 = docs_2[i]\n",
    "\n",
    "        if doc_1[\"id\"] == doc_2[\"id\"]:\n",
    "            match_count += 1\n",
    "\n",
    "    match_score = match_count / max(l1, l2)\n",
    "    return match_score\n",
    "\n",
    "\n",
    "def get_intersection_score(docs_1, docs_2):\n",
    "    def get_doc_id(doc):\n",
    "        return doc[\"id\"]\n",
    "\n",
    "    doc_ids_1 = list(map(get_doc_id, docs_1))\n",
    "    doc_ids_2 = list(map(get_doc_id, docs_2))\n",
    "\n",
    "    l1 = len(doc_ids_1)\n",
    "    l2 = len(doc_ids_2)\n",
    "\n",
    "    if min(l1, l2) == 0:\n",
    "        return 0\n",
    "\n",
    "    intersection = set(doc_ids_1).intersection(set(doc_ids_2))\n",
    "    return len(intersection) / max(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_DIR}/dataset/03_judgements.json\", \"r\") as file:\n",
    "    judgements_by_query: Dict[str, List[str]] = json.load(file)\n",
    "\n",
    "JUDGEMENTS = []\n",
    "\n",
    "for idx, query in enumerate(en_queries):\n",
    "    relevant_document_ids = judgements_by_query[query]\n",
    "\n",
    "    JUDGEMENTS.append({\n",
    "        \"model_id\": CHAT_GPT,\n",
    "        \"query_id\": idx + 1,\n",
    "        \"documents\": list(map(\n",
    "            lambda id: {\"id\": id},\n",
    "            relevant_document_ids\n",
    "        )),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVALS = {}\n",
    "\n",
    "for part, lang, model, idx in plmi():\n",
    "    RETRIEVALS[(\n",
    "        part, lang, model, idx\n",
    "    )] = json.load(open(get_retrieval_path(\n",
    "        model, get_id(part, lang, idx)\n",
    "    ), \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(retrievals, get_group_stats_path, group_iterator):\n",
    "    results = {}\n",
    "\n",
    "    for key, retrieval in retrievals.items():\n",
    "        path = get_group_stats_path(key)\n",
    "\n",
    "        similarities = list(map(\n",
    "            lambda doc: doc[\"similarity\"],\n",
    "            retrieval[\"documents\"]\n",
    "        ))\n",
    "\n",
    "        if len(similarities) == 0:\n",
    "            continue\n",
    "\n",
    "        set_attr(\n",
    "            results,\n",
    "            f\"{path}.avg\",\n",
    "            numpy.average(similarities),\n",
    "            append=True\n",
    "        )\n",
    "\n",
    "        set_attr(\n",
    "            results,\n",
    "            f\"{path}.max\",\n",
    "            numpy.max(similarities),\n",
    "            append=True\n",
    "        )\n",
    "\n",
    "        set_attr(\n",
    "            results,\n",
    "            f\"{path}.min\",\n",
    "            numpy.min(similarities),\n",
    "            append=True\n",
    "        )\n",
    "\n",
    "        set_attr(\n",
    "            results,\n",
    "            f\"{path}.std\",\n",
    "            numpy.std(similarities),\n",
    "            append=True\n",
    "        )\n",
    "\n",
    "    average = []\n",
    "    total_maxs = []\n",
    "    avg_maxs = []\n",
    "    total_mins = []\n",
    "    avg_mins = []\n",
    "    avg_stds = []\n",
    "    coeffs_from_total = []\n",
    "    coeffs_from_avg = []\n",
    "\n",
    "    for group in group_iterator:\n",
    "        path = get_group_stats_path(group)\n",
    "\n",
    "        avg_path = f\"{path}.avg\"\n",
    "        max_path = f\"{path}.max\"\n",
    "        min_path = f\"{path}.min\"\n",
    "        std_path = f\"{path}.std\"\n",
    "\n",
    "        avg_avg = numpy.max(get_attr(results, avg_path))\n",
    "        total_max = numpy.max(get_attr(results, max_path))\n",
    "        avg_max = numpy.average(get_attr(results, max_path))\n",
    "        total_min = numpy.min(get_attr(results, min_path))\n",
    "        avg_min = numpy.average(get_attr(results, min_path))\n",
    "        avg_std = numpy.average(get_attr(results, std_path))\n",
    "        coeff_from_total = avg_std / total_max\n",
    "        coeff_from_avg = avg_std / avg_max\n",
    "\n",
    "        average.append(avg_avg)\n",
    "        total_maxs.append(total_max)\n",
    "        avg_maxs.append(avg_max)\n",
    "        total_mins.append(total_min)\n",
    "        avg_mins.append(avg_min)\n",
    "        avg_stds.append(avg_std)\n",
    "        coeffs_from_total.append(coeff_from_total)\n",
    "        coeffs_from_avg.append(coeff_from_avg)\n",
    "\n",
    "    df = pandas.DataFrame({\n",
    "        \"average\": average,\n",
    "        \"total_max\": total_maxs,\n",
    "        \"avg_max\": avg_maxs,\n",
    "        \"total_min\": total_mins,\n",
    "        \"avg_min\": avg_mins,\n",
    "        \"avg_std\": avg_stds,\n",
    "        \"coeff_from_total\": coeffs_from_total,\n",
    "        \"coeff_from_avg\": coeffs_from_avg\n",
    "    })\n",
    "\n",
    "    df.index = pandas.MultiIndex.from_tuples(group_iterator)\n",
    "    df.columns = pandas.MultiIndex.from_tuples([\n",
    "        (\"\", \"avg\"),\n",
    "        (\"max\", \"total\"), (\"max\", \"average\"),\n",
    "        (\"min\", \"total\"), (\"min\", \"average\"),\n",
    "        (\"std\", \"average\"),\n",
    "        (\"coeff\", \"from_total\"), (\"coeff\", \"from_average\")\n",
    "    ])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without merging by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">max</th>\n",
       "      <th colspan=\"2\" halign=\"left\">min</th>\n",
       "      <th>std</th>\n",
       "      <th colspan=\"2\" halign=\"left\">coeff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg</th>\n",
       "      <th>total</th>\n",
       "      <th>average</th>\n",
       "      <th>total</th>\n",
       "      <th>average</th>\n",
       "      <th>average</th>\n",
       "      <th>from_total</th>\n",
       "      <th>from_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">paragraph</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">en</th>\n",
       "      <th>tgrm</th>\n",
       "      <td>0.272380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516208</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.030572</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.115264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <td>0.940128</td>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.970051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197145</td>\n",
       "      <td>0.075511</td>\n",
       "      <td>0.075810</td>\n",
       "      <td>0.077842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labse</th>\n",
       "      <td>0.720384</td>\n",
       "      <td>0.993652</td>\n",
       "      <td>0.846169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309248</td>\n",
       "      <td>0.059178</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.069936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gte</th>\n",
       "      <td>0.843834</td>\n",
       "      <td>0.990857</td>\n",
       "      <td>0.919496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328108</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>0.054334</td>\n",
       "      <td>0.058551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">sk</th>\n",
       "      <th>tgrm</th>\n",
       "      <td>0.130610</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.268057</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.025774</td>\n",
       "      <td>0.030570</td>\n",
       "      <td>0.036895</td>\n",
       "      <td>0.114042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <td>0.933340</td>\n",
       "      <td>0.991958</td>\n",
       "      <td>0.959784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355945</td>\n",
       "      <td>0.066007</td>\n",
       "      <td>0.066542</td>\n",
       "      <td>0.068772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labse</th>\n",
       "      <td>0.736134</td>\n",
       "      <td>0.972680</td>\n",
       "      <td>0.837534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400441</td>\n",
       "      <td>0.046961</td>\n",
       "      <td>0.048280</td>\n",
       "      <td>0.056070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gte</th>\n",
       "      <td>0.852503</td>\n",
       "      <td>0.977300</td>\n",
       "      <td>0.903436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387746</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.046511</td>\n",
       "      <td>0.050313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">de</th>\n",
       "      <th>tgrm</th>\n",
       "      <td>0.210203</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.313692</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.028651</td>\n",
       "      <td>0.036078</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.115012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <td>0.935851</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.960118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183805</td>\n",
       "      <td>0.084219</td>\n",
       "      <td>0.084762</td>\n",
       "      <td>0.087717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labse</th>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.960033</td>\n",
       "      <td>0.843662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392088</td>\n",
       "      <td>0.048768</td>\n",
       "      <td>0.050798</td>\n",
       "      <td>0.057805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gte</th>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.977354</td>\n",
       "      <td>0.908332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389760</td>\n",
       "      <td>0.045481</td>\n",
       "      <td>0.046534</td>\n",
       "      <td>0.050070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   max                 min            \\\n",
       "                         avg     total   average     total   average   \n",
       "paragraph en tgrm   0.272380  1.000000  0.516208  0.006098  0.030572   \n",
       "             e5     0.940128  0.996055  0.970051  0.000000  0.197145   \n",
       "             labse  0.720384  0.993652  0.846169  0.000000  0.309248   \n",
       "             gte    0.843834  0.990857  0.919496  0.000000  0.328108   \n",
       "          sk tgrm   0.130610  0.828571  0.268057  0.011111  0.025774   \n",
       "             e5     0.933340  0.991958  0.959784  0.000000  0.355945   \n",
       "             labse  0.736134  0.972680  0.837534  0.000000  0.400441   \n",
       "             gte    0.852503  0.977300  0.903436  0.000000  0.387746   \n",
       "          de tgrm   0.210203  0.785714  0.313692  0.006897  0.028651   \n",
       "             e5     0.935851  0.993590  0.960118  0.000000  0.183805   \n",
       "             labse  0.738324  0.960033  0.843662  0.000000  0.392088   \n",
       "             gte    0.827719  0.977354  0.908332  0.000000  0.389760   \n",
       "\n",
       "                         std      coeff               \n",
       "                     average from_total from_average  \n",
       "paragraph en tgrm   0.059500   0.059500     0.115264  \n",
       "             e5     0.075511   0.075810     0.077842  \n",
       "             labse  0.059178   0.059556     0.069936  \n",
       "             gte    0.053838   0.054334     0.058551  \n",
       "          sk tgrm   0.030570   0.036895     0.114042  \n",
       "             e5     0.066007   0.066542     0.068772  \n",
       "             labse  0.046961   0.048280     0.056070  \n",
       "             gte    0.045455   0.046511     0.050313  \n",
       "          de tgrm   0.036078   0.045918     0.115012  \n",
       "             e5     0.084219   0.084762     0.087717  \n",
       "             labse  0.048768   0.050798     0.057805  \n",
       "             gte    0.045481   0.046534     0.050070  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(\n",
    "    RETRIEVALS,\n",
    "    lambda key: f\"{key[0]}.{key[1]}.{key[2]}\",\n",
    "    plm()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_retrievals = {}\n",
    "\n",
    "for part, lang, model in plm():\n",
    "    queries = queries_by_language[lang]\n",
    "    retrievals = []\n",
    "\n",
    "    for idx in range(len(queries)):\n",
    "        retrieval = RETRIEVALS[(part, lang, model, idx)]\n",
    "        retrievals.append(retrieval.copy())\n",
    "\n",
    "    for retrieval in retrievals:\n",
    "        retrieval[\"documents\"] = list(filter(\n",
    "            lambda doc: doc[\"similarity\"] > 0,\n",
    "            retrieval[\"documents\"]\n",
    "        ))\n",
    "\n",
    "    max_similarity = None\n",
    "    min_similarity = None\n",
    "\n",
    "    for retrieval in retrievals:\n",
    "        for doc in retrieval[\"documents\"]:\n",
    "            similarity = doc[\"similarity\"]\n",
    "\n",
    "            if max_similarity is None:\n",
    "                max_similarity = similarity\n",
    "\n",
    "            if min_similarity is None:\n",
    "                min_similarity = similarity\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "\n",
    "            if similarity < min_similarity:\n",
    "                min_similarity = similarity\n",
    "\n",
    "    for retrieval in retrievals:\n",
    "        normalized_retrievals[(\n",
    "            retrieval[\"part\"],\n",
    "            retrieval[\"lang\"],\n",
    "            retrieval[\"model_id\"] if \"model_id\" in retrieval else PG_TGRM,\n",
    "            retrieval[\"query_id\"] - 1\n",
    "        )] = {\n",
    "            **retrieval,\n",
    "            \"documents\": list(map(\n",
    "                lambda doc: {\n",
    "                    **doc,\n",
    "                    \"similarity\": normalize(\n",
    "                        max_similarity,\n",
    "                        min_similarity,\n",
    "                        doc[\"similarity\"]\n",
    "                    )\n",
    "                },\n",
    "                retrieval[\"documents\"])\n",
    "            )\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">max</th>\n",
       "      <th colspan=\"2\" halign=\"left\">min</th>\n",
       "      <th>std</th>\n",
       "      <th colspan=\"2\" halign=\"left\">coeff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg</th>\n",
       "      <th>total</th>\n",
       "      <th>average</th>\n",
       "      <th>total</th>\n",
       "      <th>average</th>\n",
       "      <th>average</th>\n",
       "      <th>from_total</th>\n",
       "      <th>from_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">paragraph</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">en</th>\n",
       "      <th>tgrm</th>\n",
       "      <td>0.267916</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024624</td>\n",
       "      <td>0.059865</td>\n",
       "      <td>0.059865</td>\n",
       "      <td>0.116642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <td>0.551343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.787855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208048</td>\n",
       "      <td>0.080850</td>\n",
       "      <td>0.080850</td>\n",
       "      <td>0.102620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labse</th>\n",
       "      <td>0.455094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138169</td>\n",
       "      <td>0.082350</td>\n",
       "      <td>0.082350</td>\n",
       "      <td>0.115901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gte</th>\n",
       "      <td>0.532008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.808398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155101</td>\n",
       "      <td>0.082801</td>\n",
       "      <td>0.082801</td>\n",
       "      <td>0.102425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">sk</th>\n",
       "      <th>tgrm</th>\n",
       "      <td>0.146183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.314323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>0.037396</td>\n",
       "      <td>0.037396</td>\n",
       "      <td>0.118974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <td>0.479848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174609</td>\n",
       "      <td>0.089495</td>\n",
       "      <td>0.089495</td>\n",
       "      <td>0.125256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labse</th>\n",
       "      <td>0.466278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.695069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163408</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.111569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gte</th>\n",
       "      <td>0.574962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166693</td>\n",
       "      <td>0.081275</td>\n",
       "      <td>0.081275</td>\n",
       "      <td>0.108594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">de</th>\n",
       "      <th>tgrm</th>\n",
       "      <td>0.261045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.393925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027932</td>\n",
       "      <td>0.046324</td>\n",
       "      <td>0.046324</td>\n",
       "      <td>0.117597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <td>0.578455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178220</td>\n",
       "      <td>0.081467</td>\n",
       "      <td>0.081467</td>\n",
       "      <td>0.115197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labse</th>\n",
       "      <td>0.481162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166090</td>\n",
       "      <td>0.082867</td>\n",
       "      <td>0.082867</td>\n",
       "      <td>0.113880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gte</th>\n",
       "      <td>0.497874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.767469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161675</td>\n",
       "      <td>0.082256</td>\n",
       "      <td>0.082256</td>\n",
       "      <td>0.107179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               max             min                 std  \\\n",
       "                         avg total   average total   average   average   \n",
       "paragraph en tgrm   0.267916   1.0  0.513240   0.0  0.024624  0.059865   \n",
       "             e5     0.551343   1.0  0.787855   0.0  0.208048  0.080850   \n",
       "             labse  0.455094   1.0  0.710521   0.0  0.138169  0.082350   \n",
       "             gte    0.532008   1.0  0.808398   0.0  0.155101  0.082801   \n",
       "          sk tgrm   0.146183   1.0  0.314323   0.0  0.017937  0.037396   \n",
       "             e5     0.479848   1.0  0.714494   0.0  0.174609  0.089495   \n",
       "             labse  0.466278   1.0  0.695069   0.0  0.163408  0.077548   \n",
       "             gte    0.574962   1.0  0.748432   0.0  0.166693  0.081275   \n",
       "          de tgrm   0.261045   1.0  0.393925   0.0  0.027932  0.046324   \n",
       "             e5     0.578455   1.0  0.707201   0.0  0.178220  0.081467   \n",
       "             labse  0.481162   1.0  0.727672   0.0  0.166090  0.082867   \n",
       "             gte    0.497874   1.0  0.767469   0.0  0.161675  0.082256   \n",
       "\n",
       "                        coeff               \n",
       "                   from_total from_average  \n",
       "paragraph en tgrm    0.059865     0.116642  \n",
       "             e5      0.080850     0.102620  \n",
       "             labse   0.082350     0.115901  \n",
       "             gte     0.082801     0.102425  \n",
       "          sk tgrm    0.037396     0.118974  \n",
       "             e5      0.089495     0.125256  \n",
       "             labse   0.077548     0.111569  \n",
       "             gte     0.081275     0.108594  \n",
       "          de tgrm    0.046324     0.117597  \n",
       "             e5      0.081467     0.115197  \n",
       "             labse   0.082867     0.113880  \n",
       "             gte     0.082256     0.107179  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(\n",
    "    normalized_retrievals,\n",
    "    lambda key: f\"{key[0]}.{key[1]}.{key[2]}\",\n",
    "    plm()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieval(params, coeff):\n",
    "    part, lang, model, idx = params\n",
    "\n",
    "    if model == CHAT_GPT:\n",
    "        retrieval = JUDGEMENTS[idx]\n",
    "        top_docs = retrieval[\"documents\"]\n",
    "    else:\n",
    "        retrieval = normalized_retrievals[(part, lang, model, idx)]\n",
    "        top_docs = get_top_docs(retrieval[\"documents\"], coeff)\n",
    "\n",
    "    length = len(top_docs)\n",
    "\n",
    "    return top_docs, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part, coeff, pair         counts     ordering      intersection\n",
      "\n",
      "[paragraph]\n",
      "  [en]\n",
      "    [0.05]\n",
      "      tgrm/e5             2/2        0.51896       0.56336\n",
      "      tgrm/labse          2/2        0.53145       0.57792\n",
      "      tgrm/gte            2/1        0.57815       0.61526\n",
      "      tgrm/chat-gpt       2/5        -             0.41167\n",
      "      e5/labse            2/2        0.52309       0.58501\n",
      "      e5/gte              2/1        0.63541       0.67858\n",
      "      e5/chat-gpt         2/5        -             0.45485\n",
      "      labse/gte           2/1        0.61293       0.65610\n",
      "      labse/chat-gpt      2/5        -             0.43990\n",
      "      gte/chat-gpt        1/5        -             0.55481\n",
      "\n",
      "    [0.10]\n",
      "      tgrm/e5             2/3        0.45118       0.52713\n",
      "      tgrm/labse          2/3        0.47729       0.54482\n",
      "      tgrm/gte            2/2        0.53954       0.59601\n",
      "      tgrm/chat-gpt       2/5        -             0.40982\n",
      "      e5/labse            3/3        0.44740       0.54508\n",
      "      e5/gte              3/2        0.55238       0.61478\n",
      "      e5/chat-gpt         3/5        -             0.42870\n",
      "      labse/gte           3/2        0.54080       0.61498\n",
      "      labse/chat-gpt      3/5        -             0.41765\n",
      "      gte/chat-gpt        2/5        -             0.56837\n",
      "\n",
      "    [0.20]\n",
      "      tgrm/e5             4/12       0.25372       0.32728\n",
      "      tgrm/labse          4/8        0.31348       0.39366\n",
      "      tgrm/gte            4/3        0.40947       0.48654\n",
      "      tgrm/chat-gpt       4/5        -             0.37480\n",
      "      e5/labse           12/8        0.23858       0.36294\n",
      "      e5/gte             12/3        0.31053       0.39794\n",
      "      e5/chat-gpt        12/5        -             0.30769\n",
      "      labse/gte           8/3        0.35521       0.44118\n",
      "      labse/chat-gpt      8/5        -             0.31681\n",
      "      gte/chat-gpt        3/5        -             0.50244\n",
      "\n",
      "    [0.25]\n",
      "      tgrm/e5             5/25       0.16772       0.24713\n",
      "      tgrm/labse          5/15       0.22134       0.30541\n",
      "      tgrm/gte            5/7        0.33277       0.40835\n",
      "      tgrm/chat-gpt       5/5        -             0.35632\n",
      "      e5/labse           25/15       0.14071       0.29284\n",
      "      e5/gte             25/7        0.20067       0.30284\n",
      "      e5/chat-gpt        25/5        -             0.22946\n",
      "      labse/gte          15/7        0.24083       0.34253\n",
      "      labse/chat-gpt     15/5        -             0.25238\n",
      "      gte/chat-gpt        7/5        -             0.44152\n",
      "\n",
      "    [0.30]\n",
      "      tgrm/e5             8/46       0.10420       0.18610\n",
      "      tgrm/labse          8/26       0.15621       0.24802\n",
      "      tgrm/gte            8/12       0.24127       0.33354\n",
      "      tgrm/chat-gpt       8/5        -             0.34354\n",
      "      e5/labse           46/26       0.08724       0.28189\n",
      "      e5/gte             46/12       0.12164       0.23545\n",
      "      e5/chat-gpt        46/5        -             0.15566\n",
      "      labse/gte          26/12       0.15228       0.27658\n",
      "      labse/chat-gpt     26/5        -             0.19205\n",
      "      gte/chat-gpt       12/5        -             0.35704\n",
      "\n",
      "    [1.00]\n",
      "      tgrm/e5           396/392      0.00792       0.99044\n",
      "      tgrm/labse        396/388      0.00749       0.98065\n",
      "      tgrm/gte          396/387      0.00764       0.97719\n",
      "      tgrm/chat-gpt     396/5        -             0.01143\n",
      "      e5/labse          392/388      0.00834       0.97473\n",
      "      e5/gte            392/387      0.00902       0.97162\n",
      "      e5/chat-gpt       392/5        -             0.01150\n",
      "      labse/gte         388/387      0.00863       0.97670\n",
      "      labse/chat-gpt    388/5        -             0.01132\n",
      "      gte/chat-gpt      387/5        -             0.01144\n",
      "\n",
      "  [sk]\n",
      "    [0.05]\n",
      "      tgrm/e5             2/3        0.12909       0.20178\n",
      "      tgrm/labse          2/2        0.12653       0.14798\n",
      "      tgrm/gte            2/1        0.14230       0.15916\n",
      "      tgrm/chat-gpt       2/5        -             0.10054\n",
      "      e5/labse            3/2        0.13530       0.17249\n",
      "      e5/gte              3/1        0.13444       0.17151\n",
      "      e5/chat-gpt         3/5        -             0.11345\n",
      "      labse/gte           2/1        0.47164       0.54102\n",
      "      labse/chat-gpt      2/5        -             0.34901\n",
      "      gte/chat-gpt        1/5        -             0.50713\n",
      "\n",
      "    [0.10]\n",
      "      tgrm/e5             2/6        0.09213       0.19848\n",
      "      tgrm/labse          2/3        0.09809       0.13606\n",
      "      tgrm/gte            2/3        0.11065       0.14300\n",
      "      tgrm/chat-gpt       2/5        -             0.09411\n",
      "      e5/labse            6/3        0.11085       0.16473\n",
      "      e5/gte              6/3        0.11524       0.16421\n",
      "      e5/chat-gpt         6/5        -             0.10796\n",
      "      labse/gte           3/3        0.38674       0.48587\n",
      "      labse/chat-gpt      3/5        -             0.33946\n",
      "      gte/chat-gpt        3/5        -             0.48707\n",
      "\n",
      "    [0.20]\n",
      "      tgrm/e5             4/21       0.04282       0.16300\n",
      "      tgrm/labse          4/11       0.04884       0.11789\n",
      "      tgrm/gte            4/8        0.06563       0.12989\n",
      "      tgrm/chat-gpt       4/5        -             0.09894\n",
      "      e5/labse           21/11       0.03586       0.12365\n",
      "      e5/gte             21/8        0.03564       0.10420\n",
      "      e5/chat-gpt        21/5        -             0.06843\n",
      "      labse/gte          11/8        0.21421       0.34228\n",
      "      labse/chat-gpt     11/5        -             0.24717\n",
      "      gte/chat-gpt        8/5        -             0.37407\n",
      "\n",
      "    [0.25]\n",
      "      tgrm/e5             6/32       0.02264       0.14472\n",
      "      tgrm/labse          6/21       0.03594       0.11316\n",
      "      tgrm/gte            6/14       0.04708       0.12308\n",
      "      tgrm/chat-gpt       6/5        -             0.09482\n",
      "      e5/labse           32/21       0.02191       0.13559\n",
      "      e5/gte             32/14       0.01866       0.10712\n",
      "      e5/chat-gpt        32/5        -             0.04780\n",
      "      labse/gte          21/14       0.14534       0.30558\n",
      "      labse/chat-gpt     21/5        -             0.18770\n",
      "      gte/chat-gpt       14/5        -             0.30369\n",
      "\n",
      "    [0.30]\n",
      "      tgrm/e5             9/46       0.01406       0.13985\n",
      "      tgrm/labse          9/37       0.02251       0.10777\n",
      "      tgrm/gte            9/24       0.03106       0.11545\n",
      "      tgrm/chat-gpt       9/5        -             0.08067\n",
      "      e5/labse           46/37       0.01293       0.16328\n",
      "      e5/gte             46/24       0.01023       0.12427\n",
      "      e5/chat-gpt        46/5        -             0.03840\n",
      "      labse/gte          37/24       0.08376       0.27980\n",
      "      labse/chat-gpt     37/5        -             0.14059\n",
      "      gte/chat-gpt       24/5        -             0.22184\n",
      "\n",
      "    [1.00]\n",
      "      tgrm/e5           396/393      0.00661       0.99145\n",
      "      tgrm/labse        396/395      0.00543       0.99677\n",
      "      tgrm/gte          396/395      0.00557       0.99629\n",
      "      tgrm/chat-gpt     396/5        -             0.01143\n",
      "      e5/labse          393/395      0.00528       0.98990\n",
      "      e5/gte            393/395      0.00505       0.99015\n",
      "      e5/chat-gpt       393/5        -             0.01149\n",
      "      labse/gte         395/395      0.00816       0.99451\n",
      "      labse/chat-gpt    395/5        -             0.01145\n",
      "      gte/chat-gpt      395/5        -             0.01146\n",
      "\n",
      "  [de]\n",
      "    [0.05]\n",
      "      tgrm/e5             2/2        0.18520       0.25642\n",
      "      tgrm/labse          2/2        0.17399       0.20780\n",
      "      tgrm/gte            2/2        0.18932       0.21447\n",
      "      tgrm/chat-gpt       2/5        -             0.16842\n",
      "      e5/labse            2/2        0.20599       0.26197\n",
      "      e5/gte              2/2        0.22696       0.27566\n",
      "      e5/chat-gpt         2/5        -             0.20446\n",
      "      labse/gte           2/2        0.48570       0.53776\n",
      "      labse/chat-gpt      2/5        -             0.35069\n",
      "      gte/chat-gpt        2/5        -             0.52778\n",
      "\n",
      "    [0.10]\n",
      "      tgrm/e5             2/4        0.14089       0.24898\n",
      "      tgrm/labse          2/3        0.14187       0.20662\n",
      "      tgrm/gte            2/2        0.15650       0.20316\n",
      "      tgrm/chat-gpt       2/5        -             0.16236\n",
      "      e5/labse            4/3        0.14623       0.24625\n",
      "      e5/gte              4/2        0.15567       0.23506\n",
      "      e5/chat-gpt         4/5        -             0.18560\n",
      "      labse/gte           3/2        0.40470       0.49981\n",
      "      labse/chat-gpt      3/5        -             0.34139\n",
      "      gte/chat-gpt        2/5        -             0.51252\n",
      "\n",
      "    [0.20]\n",
      "      tgrm/e5             5/14       0.07532       0.22131\n",
      "      tgrm/labse          5/11       0.08889       0.18295\n",
      "      tgrm/gte            5/7        0.11257       0.19287\n",
      "      tgrm/chat-gpt       5/5        -             0.15358\n",
      "      e5/labse           14/11       0.07469       0.21822\n",
      "      e5/gte             14/7        0.07813       0.18582\n",
      "      e5/chat-gpt        14/5        -             0.12563\n",
      "      labse/gte          11/7        0.24430       0.37341\n",
      "      labse/chat-gpt     11/5        -             0.25855\n",
      "      gte/chat-gpt        7/5        -             0.42463\n",
      "\n",
      "    [0.25]\n",
      "      tgrm/e5             7/23       0.05648       0.20486\n",
      "      tgrm/labse          7/19       0.05496       0.16797\n",
      "      tgrm/gte            7/12       0.07780       0.17769\n",
      "      tgrm/chat-gpt       7/5        -             0.14585\n",
      "      e5/labse           23/19       0.04280       0.20978\n",
      "      e5/gte             23/12       0.05084       0.18037\n",
      "      e5/chat-gpt        23/5        -             0.09499\n",
      "      labse/gte          19/12       0.17207       0.33445\n",
      "      labse/chat-gpt     19/5        -             0.20515\n",
      "      gte/chat-gpt       12/5        -             0.35421\n",
      "\n",
      "    [0.30]\n",
      "      tgrm/e5            10/39       0.03952       0.19034\n",
      "      tgrm/labse         10/32       0.03689       0.15676\n",
      "      tgrm/gte           10/19       0.05842       0.16789\n",
      "      tgrm/chat-gpt      10/5        -             0.13267\n",
      "      e5/labse           39/32       0.02814       0.22828\n",
      "      e5/gte             39/19       0.03727       0.19397\n",
      "      e5/chat-gpt        39/5        -             0.07448\n",
      "      labse/gte          32/19       0.10064       0.28621\n",
      "      labse/chat-gpt     32/5        -             0.15411\n",
      "      gte/chat-gpt       19/5        -             0.28487\n",
      "\n",
      "    [1.00]\n",
      "      tgrm/e5           396/392      0.00615       0.98865\n",
      "      tgrm/labse        396/395      0.00588       0.99651\n",
      "      tgrm/gte          396/395      0.00543       0.99642\n",
      "      tgrm/chat-gpt     396/5        -             0.01143\n",
      "      e5/labse          392/395      0.00587       0.98790\n",
      "      e5/gte            392/395      0.00578       0.98885\n",
      "      e5/chat-gpt       392/5        -             0.01152\n",
      "      labse/gte         395/395      0.00830       0.99448\n",
      "      labse/chat-gpt    395/5        -             0.01146\n",
      "      gte/chat-gpt      395/5        -             0.01146\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"part, coeff, pair\".ljust(26) +\n",
    "      \"counts\".ljust(11) +\n",
    "      \"ordering\".ljust(14) +\n",
    "      \"intersection\"\n",
    "      )\n",
    "\n",
    "print()\n",
    "\n",
    "for part in PARTS:\n",
    "    print(f\"[{part}]\")\n",
    "    for lang in LANGUAGES:\n",
    "        print(2*SPACE + f\"[{lang}]\")\n",
    "\n",
    "        for coeff in COEFFS:\n",
    "            print(4*SPACE + \"[{:.2f}]\".format(coeff))\n",
    "            queries = queries_by_language[lang]\n",
    "\n",
    "            for model1, model2 in MODEL_COMBINATIONS:\n",
    "                lengths_1 = []\n",
    "                lengths_2 = []\n",
    "                ordering_scores = []\n",
    "                intersection_scores = []\n",
    "\n",
    "                for idx, query in enumerate(queries):\n",
    "                    docs_1, l1 = get_retrieval(\n",
    "                        (part, lang, model1, idx), coeff)\n",
    "\n",
    "                    docs_2, l2 = get_retrieval(\n",
    "                        (part, lang, model2, idx), coeff)\n",
    "\n",
    "                    lengths_1.append(l1)\n",
    "                    lengths_2.append(l2)\n",
    "\n",
    "                    if not CHAT_GPT in [model1, model2]:\n",
    "                        ordering_scores.append(\n",
    "                            get_ordering_score(docs_1, docs_2)\n",
    "                        )\n",
    "\n",
    "                    intersection_scores.append(\n",
    "                        get_intersection_score(docs_1, docs_2)\n",
    "                    )\n",
    "\n",
    "                avg_length_1 = numpy.average(lengths_1)\n",
    "                avg_length_2 = numpy.average(lengths_2)\n",
    "\n",
    "                if len(ordering_scores):\n",
    "                    avg_ordering_score = numpy.average(\n",
    "                        ordering_scores\n",
    "                    ).round(5)\n",
    "                else:\n",
    "                    avg_ordering_score = None\n",
    "\n",
    "                avg_intersection_score = numpy.average(\n",
    "                    intersection_scores\n",
    "                ).round(5)\n",
    "\n",
    "                print(\n",
    "                    6*SPACE + f\"{model1}/{model2}\".ljust(15),\n",
    "                    \"{:.0f}\".format(avg_length_1).rjust(5)\n",
    "                    + \"/\" +\n",
    "                    \"{:.0f}\".format(avg_length_2).ljust(5),\n",
    "                    3*SPACE +\n",
    "                    (\"{:.5f}\".format(\n",
    "                        avg_ordering_score) if avg_ordering_score is not None else \"-\".ljust(7)),\n",
    "                    6*SPACE + \"{:.5f}\".format(avg_intersection_score)\n",
    "                )\n",
    "\n",
    "            print()\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With merging by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_retrievals = {}\n",
    "\n",
    "for part in PARTS:\n",
    "    for model in ALL_MODELS:\n",
    "        for idx in range(len(queries_by_language[\"en\"])):\n",
    "            documents = []\n",
    "\n",
    "            for lang in LANGUAGES:\n",
    "                retrieval = RETRIEVALS[(part, lang, model, idx)]                \n",
    "                documents.extend(retrieval[\"documents\"].copy())\n",
    "\n",
    "            # Sort by similarity, descending\n",
    "            documents.sort(key=lambda doc: doc[\"similarity\"], reverse=True)\n",
    "\n",
    "            # Remove duplicates\n",
    "            duplicate_ids = set()\n",
    "\n",
    "            def is_duplicate(doc):\n",
    "                if doc[\"id\"] in duplicate_ids:\n",
    "                    return True\n",
    "\n",
    "                duplicate_ids.add(doc[\"id\"])\n",
    "                return False\n",
    "\n",
    "            documents = list(filter(\n",
    "                lambda doc: not is_duplicate(doc),\n",
    "                documents\n",
    "            ))\n",
    "\n",
    "            merged_retrievals[(part, model, idx)] = {\n",
    "                \"part\": part,\n",
    "                \"model_id\": model,\n",
    "                \"query_id\": idx + 1,\n",
    "                \"documents\": documents\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">max</th>\n",
       "      <th colspan=\"2\" halign=\"left\">min</th>\n",
       "      <th>std</th>\n",
       "      <th colspan=\"2\" halign=\"left\">coeff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg</th>\n",
       "      <th>total</th>\n",
       "      <th>average</th>\n",
       "      <th>total</th>\n",
       "      <th>average</th>\n",
       "      <th>average</th>\n",
       "      <th>from_total</th>\n",
       "      <th>from_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">paragraph</th>\n",
       "      <th>tgrm</th>\n",
       "      <td>0.275490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.527923</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.043162</td>\n",
       "      <td>0.059096</td>\n",
       "      <td>0.059096</td>\n",
       "      <td>0.111941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <td>0.942810</td>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.972647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729370</td>\n",
       "      <td>0.019244</td>\n",
       "      <td>0.019320</td>\n",
       "      <td>0.019785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labse</th>\n",
       "      <td>0.745886</td>\n",
       "      <td>0.993652</td>\n",
       "      <td>0.862686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545362</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>0.038671</td>\n",
       "      <td>0.044541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gte</th>\n",
       "      <td>0.854049</td>\n",
       "      <td>0.990857</td>\n",
       "      <td>0.933446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589032</td>\n",
       "      <td>0.031176</td>\n",
       "      <td>0.031463</td>\n",
       "      <td>0.033399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                max                 min                 std  \\\n",
       "                      avg     total   average     total   average   average   \n",
       "paragraph tgrm   0.275490  1.000000  0.527923  0.020833  0.043162  0.059096   \n",
       "          e5     0.942810  0.996055  0.972647  0.000000  0.729370  0.019244   \n",
       "          labse  0.745886  0.993652  0.862686  0.000000  0.545362  0.038425   \n",
       "          gte    0.854049  0.990857  0.933446  0.000000  0.589032  0.031176   \n",
       "\n",
       "                     coeff               \n",
       "                from_total from_average  \n",
       "paragraph tgrm    0.059096     0.111941  \n",
       "          e5      0.019320     0.019785  \n",
       "          labse   0.038671     0.044541  \n",
       "          gte     0.031463     0.033399  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(\n",
    "    merged_retrievals,\n",
    "    lambda key: f\"{key[0]}.{key[1]}\",\n",
    "    [(part, model) for part in PARTS for model in ALL_MODELS]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_normalized_retrievals = {}\n",
    "merged_normalization_params = {}\n",
    "\n",
    "for part in PARTS:\n",
    "    for model in ALL_MODELS:\n",
    "        tmp_retrievals = []\n",
    "\n",
    "        max_similarity = None\n",
    "        min_similarity = None\n",
    "\n",
    "        for idx in range(len(queries_by_language[\"en\"])):\n",
    "            retrieval = merged_retrievals[(part, model, idx)]\n",
    "\n",
    "            tmp_retrievals.append({\n",
    "                **retrieval,\n",
    "                \"documents\": list(filter(\n",
    "                    lambda doc: doc[\"similarity\"] > 0,\n",
    "                    retrieval[\"documents\"]\n",
    "                ))\n",
    "            })\n",
    "\n",
    "        for retrieval in tmp_retrievals:\n",
    "            for doc in retrieval[\"documents\"]:\n",
    "                similarity = doc[\"similarity\"]\n",
    "\n",
    "                if max_similarity is None:\n",
    "                    max_similarity = similarity\n",
    "\n",
    "                if min_similarity is None:\n",
    "                    min_similarity = similarity\n",
    "\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "\n",
    "                if similarity < min_similarity:\n",
    "                    min_similarity = similarity\n",
    "\n",
    "        merged_normalization_params[(part, model)] = (\n",
    "            max_similarity,\n",
    "            min_similarity\n",
    "        )\n",
    "\n",
    "        for retrieval in tmp_retrievals:\n",
    "            merged_normalized_retrievals[(\n",
    "                part, model, retrieval[\"query_id\"] - 1\n",
    "            )] = {\n",
    "                **retrieval,\n",
    "                \"documents\": list(map(\n",
    "                    lambda doc: {\n",
    "                        **doc,\n",
    "                        \"similarity\": normalize(\n",
    "                            max_similarity,\n",
    "                            min_similarity,\n",
    "                            doc[\"similarity\"]\n",
    "                        )\n",
    "                    },\n",
    "                    retrieval[\"documents\"]\n",
    "                ))\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">max</th>\n",
       "      <th colspan=\"2\" halign=\"left\">min</th>\n",
       "      <th>std</th>\n",
       "      <th colspan=\"2\" halign=\"left\">coeff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg</th>\n",
       "      <th>total</th>\n",
       "      <th>average</th>\n",
       "      <th>total</th>\n",
       "      <th>average</th>\n",
       "      <th>average</th>\n",
       "      <th>from_total</th>\n",
       "      <th>from_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">paragraph</th>\n",
       "      <th>tgrm</th>\n",
       "      <td>0.260074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022803</td>\n",
       "      <td>0.060354</td>\n",
       "      <td>0.060354</td>\n",
       "      <td>0.116540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5</th>\n",
       "      <td>0.585043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188035</td>\n",
       "      <td>0.090005</td>\n",
       "      <td>0.090005</td>\n",
       "      <td>0.112569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labse</th>\n",
       "      <td>0.490092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>0.074566</td>\n",
       "      <td>0.074566</td>\n",
       "      <td>0.102079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gte</th>\n",
       "      <td>0.546133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138055</td>\n",
       "      <td>0.083493</td>\n",
       "      <td>0.083493</td>\n",
       "      <td>0.103137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            max             min                 std  \\\n",
       "                      avg total   average total   average   average   \n",
       "paragraph tgrm   0.260074   1.0  0.517879   0.0  0.022803  0.060354   \n",
       "          e5     0.585043   1.0  0.799554   0.0  0.188035  0.090005   \n",
       "          labse  0.490092   1.0  0.730469   0.0  0.194362  0.074566   \n",
       "          gte    0.546133   1.0  0.809538   0.0  0.138055  0.083493   \n",
       "\n",
       "                     coeff               \n",
       "                from_total from_average  \n",
       "paragraph tgrm    0.060354     0.116540  \n",
       "          e5      0.090005     0.112569  \n",
       "          labse   0.074566     0.102079  \n",
       "          gte     0.083493     0.103137  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(\n",
    "    merged_normalized_retrievals,\n",
    "    lambda key: f\"{key[0]}.{key[1]}\",\n",
    "    [(part, model) for part in PARTS for model in ALL_MODELS]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieval(params, coeff):\n",
    "    part, model, idx = params\n",
    "\n",
    "    if model == CHAT_GPT:\n",
    "        retrieval = JUDGEMENTS[idx]\n",
    "        top_docs = retrieval[\"documents\"]\n",
    "    else:\n",
    "        retrieval = merged_normalized_retrievals[(part, model, idx)]\n",
    "        top_docs = get_top_docs(retrieval[\"documents\"], coeff)\n",
    "\n",
    "    length = len(top_docs)\n",
    "\n",
    "    return top_docs, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part, coeff, pair         counts     ordering      intersection\n",
      "\n",
      "[paragraph]\n",
      "  [0.05]\n",
      "      tgrm/e5             1/2        0.46451       0.51850\n",
      "      tgrm/labse          1/2        0.51878       0.56697\n",
      "      tgrm/gte            1/1        0.60107       0.64054\n",
      "      tgrm/chat-gpt       1/5        -             0.42002\n",
      "      e5/labse            2/2        0.49147       0.56915\n",
      "      e5/gte              2/1        0.59083       0.65048\n",
      "      e5/chat-gpt         2/5        -             0.44021\n",
      "      labse/gte           2/1        0.57231       0.63018\n",
      "      labse/chat-gpt      2/5        -             0.41093\n",
      "      gte/chat-gpt        1/5        -             0.56716\n",
      "\n",
      "  [0.10]\n",
      "      tgrm/e5             2/4        0.38428       0.45784\n",
      "      tgrm/labse          2/3        0.45002       0.52032\n",
      "      tgrm/gte            2/2        0.55122       0.60677\n",
      "      tgrm/chat-gpt       2/5        -             0.42026\n",
      "      e5/labse            4/3        0.40277       0.51249\n",
      "      e5/gte              4/2        0.48631       0.55766\n",
      "      e5/chat-gpt         4/5        -             0.39879\n",
      "      labse/gte           3/2        0.49619       0.56600\n",
      "      labse/chat-gpt      3/5        -             0.38670\n",
      "      gte/chat-gpt        2/5        -             0.56590\n",
      "\n",
      "  [0.20]\n",
      "      tgrm/e5             4/16       0.19853       0.25492\n",
      "      tgrm/labse          4/12       0.26434       0.33603\n",
      "      tgrm/gte            4/4        0.41884       0.49899\n",
      "      tgrm/chat-gpt       4/5        -             0.39136\n",
      "      e5/labse           16/12       0.18835       0.33750\n",
      "      e5/gte             16/4        0.25640       0.33866\n",
      "      e5/chat-gpt        16/5        -             0.25409\n",
      "      labse/gte          12/4        0.30183       0.39055\n",
      "      labse/chat-gpt     12/5        -             0.27773\n",
      "      gte/chat-gpt        4/5        -             0.50777\n",
      "\n",
      "  [0.25]\n",
      "      tgrm/e5             5/29       0.12825       0.18708\n",
      "      tgrm/labse          5/22       0.18022       0.25744\n",
      "      tgrm/gte            5/7        0.33154       0.41212\n",
      "      tgrm/chat-gpt       5/5        -             0.37451\n",
      "      e5/labse           29/22       0.10548       0.30075\n",
      "      e5/gte             29/7        0.14894       0.23789\n",
      "      e5/chat-gpt        29/5        -             0.17827\n",
      "      labse/gte          22/7        0.19058       0.29912\n",
      "      labse/chat-gpt     22/5        -             0.21345\n",
      "      gte/chat-gpt        7/5        -             0.44002\n",
      "\n",
      "  [0.30]\n",
      "      tgrm/e5             7/51       0.07978       0.14112\n",
      "      tgrm/labse          7/41       0.10939       0.18695\n",
      "      tgrm/gte            7/12       0.22226       0.30919\n",
      "      tgrm/chat-gpt       7/5        -             0.35477\n",
      "      e5/labse           51/41       0.06066       0.30984\n",
      "      e5/gte             51/12       0.09211       0.19852\n",
      "      e5/chat-gpt        51/5        -             0.12335\n",
      "      labse/gte          41/12       0.11074       0.24053\n",
      "      labse/chat-gpt     41/5        -             0.15114\n",
      "      gte/chat-gpt       12/5        -             0.34915\n",
      "\n",
      "  [1.00]\n",
      "      tgrm/e5           396/396      0.00696       0.99928\n",
      "      tgrm/labse        396/396      0.00799       0.99955\n",
      "      tgrm/gte          396/396      0.00746       0.99918\n",
      "      tgrm/chat-gpt     396/5        -             0.01143\n",
      "      e5/labse          396/396      0.00831       0.99885\n",
      "      e5/gte            396/396      0.00887       0.99868\n",
      "      e5/chat-gpt       396/5        -             0.01144\n",
      "      labse/gte         396/396      0.00912       0.99892\n",
      "      labse/chat-gpt    396/5        -             0.01143\n",
      "      gte/chat-gpt      396/5        -             0.01144\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"part, coeff, pair\".ljust(26) +\n",
    "      \"counts\".ljust(11) +\n",
    "      \"ordering\".ljust(14) +\n",
    "      \"intersection\"\n",
    "      )\n",
    "\n",
    "print()\n",
    "\n",
    "for part in PARTS:\n",
    "    print(f\"[{part}]\")\n",
    "\n",
    "    for coeff in COEFFS:\n",
    "        print(2*SPACE + \"[{:.2f}]\".format(coeff))\n",
    "        queries = queries_by_language[lang]\n",
    "\n",
    "        for model1, model2 in MODEL_COMBINATIONS:\n",
    "            lengths_1 = []\n",
    "            lengths_2 = []\n",
    "            ordering_scores = []\n",
    "            intersection_scores = []\n",
    "\n",
    "            for idx, query in enumerate(queries):\n",
    "                docs_1, l1 = get_retrieval(\n",
    "                    (part, model1, idx), coeff)\n",
    "\n",
    "                docs_2, l2 = get_retrieval(\n",
    "                    (part, model2, idx), coeff)\n",
    "\n",
    "                lengths_1.append(l1)\n",
    "                lengths_2.append(l2)\n",
    "\n",
    "                if not CHAT_GPT in [model1, model2]:\n",
    "                    ordering_scores.append(\n",
    "                        get_ordering_score(docs_1, docs_2)\n",
    "                    )\n",
    "\n",
    "                intersection_scores.append(\n",
    "                    get_intersection_score(docs_1, docs_2)\n",
    "                )\n",
    "\n",
    "            avg_length_1 = numpy.average(lengths_1)\n",
    "            avg_length_2 = numpy.average(lengths_2)\n",
    "\n",
    "            if len(ordering_scores):\n",
    "                avg_ordering_score = numpy.average(\n",
    "                    ordering_scores\n",
    "                ).round(5)\n",
    "            else:\n",
    "                avg_ordering_score = None\n",
    "\n",
    "            avg_intersection_score = numpy.average(\n",
    "                intersection_scores\n",
    "            ).round(5)\n",
    "\n",
    "            print(\n",
    "                6*SPACE + f\"{model1}/{model2}\".ljust(15),\n",
    "                \"{:.0f}\".format(avg_length_1).rjust(5)\n",
    "                + \"/\" +\n",
    "                \"{:.0f}\".format(avg_length_2).ljust(5),\n",
    "                3*SPACE +\n",
    "                (\"{:.5f}\".format(\n",
    "                    avg_ordering_score) if avg_ordering_score is not None else \"-\".ljust(7)),\n",
    "                6*SPACE + \"{:.5f}\".format(avg_intersection_score)\n",
    "            )\n",
    "\n",
    "        print()\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
