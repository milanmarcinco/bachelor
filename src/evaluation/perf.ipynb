{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERF_DIR = \"../../data/perf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://le-terror:9090/api/v1/query_range\"\n",
    "max_data_points = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_usage_merge_fn(accumulator, query_result):\n",
    "    for container in query_result[\"data\"][\"result\"]:\n",
    "        container_name = container[\"metric\"][\"name\"]\n",
    "\n",
    "        if container_name not in accumulator:\n",
    "            accumulator[container_name] = []\n",
    "\n",
    "        for sample in container[\"values\"]:\n",
    "            accumulator[container_name].append(sample)\n",
    "\n",
    "\n",
    "def mem_usage_merge_fn(accumulator, query_result):\n",
    "    for container in query_result[\"data\"][\"result\"]:\n",
    "        container_name = container[\"metric\"][\"name\"]\n",
    "\n",
    "        if container_name not in accumulator:\n",
    "            accumulator[container_name] = []\n",
    "\n",
    "        for sample in container[\"values\"]:\n",
    "            accumulator[container_name].append(sample)\n",
    "\n",
    "\n",
    "def disk_usage_merge_fn(accumulator, query_result):\n",
    "    for device in query_result[\"data\"][\"result\"]:\n",
    "        device_name = device[\"metric\"][\"device\"]\n",
    "\n",
    "        if device_name not in accumulator:\n",
    "            accumulator[device_name] = []\n",
    "\n",
    "        for sample in device[\"values\"]:\n",
    "            accumulator[device_name].append(sample)\n",
    "\n",
    "\n",
    "def gpu_usage_merge_fn(accumulator, query_result):\n",
    "    for gpu in query_result[\"data\"][\"result\"]:\n",
    "        gpu_name = gpu[\"metric\"][\"uuid\"]\n",
    "\n",
    "        if gpu_name not in accumulator:\n",
    "            accumulator[gpu_name] = []\n",
    "\n",
    "        for sample in gpu[\"values\"]:\n",
    "            accumulator[gpu_name].append(sample)\n",
    "\n",
    "\n",
    "def gpu_mem_usage_merge_fn(accumulator, query_result):\n",
    "    for gpu in query_result[\"data\"][\"result\"]:\n",
    "        gpu_name = gpu[\"metric\"][\"uuid\"]\n",
    "\n",
    "        if gpu_name not in accumulator:\n",
    "            accumulator[gpu_name] = []\n",
    "\n",
    "        for sample in gpu[\"values\"]:\n",
    "            accumulator[gpu_name].append(sample)\n",
    "\n",
    "\n",
    "def gpu_power_draw_merge_fn(accumulator, query_result):\n",
    "    for gpu in query_result[\"data\"][\"result\"]:\n",
    "        gpu_name = gpu[\"metric\"][\"uuid\"]\n",
    "\n",
    "        if gpu_name not in accumulator:\n",
    "            accumulator[gpu_name] = []\n",
    "\n",
    "        for sample in gpu[\"values\"]:\n",
    "            accumulator[gpu_name].append(sample)\n",
    "\n",
    "\n",
    "queries = {\n",
    "    \"cpu_usage\": {\n",
    "        \"query\": \"container_cpu_usage_seconds_total{image=~\\\"getmeili/meilisearch:latest|postgres-contrib|bachelor-script\\\"}\",\n",
    "        \"merge_fn\": cpu_usage_merge_fn\n",
    "    },\n",
    "    \"mem_usage\": {\n",
    "        \"query\": \"container_memory_usage_bytes{image=~\\\"getmeili/meilisearch:latest|postgres-contrib|bachelor-script\\\"}\",\n",
    "        \"merge_fn\": mem_usage_merge_fn\n",
    "    },\n",
    "    \"disk_usage\": {\n",
    "        \"query\": \"container_fs_usage_bytes{device=\\\"/dev/nvme0n1p1\\\", id=\\\"/\\\"}\",\n",
    "        \"merge_fn\": disk_usage_merge_fn\n",
    "    },\n",
    "    \"gpu_usage\": {\n",
    "        \"query\": \"nvidia_smi_utilization_gpu_ratio{uuid=\\\"5e80926d-27b6-a1dc-cc4f-64f033face7f\\\"}\",\n",
    "        \"merge_fn\": gpu_usage_merge_fn\n",
    "    },\n",
    "    \"gpu_mem_usage\": {\n",
    "        \"query\": \"nvidia_smi_memory_used_bytes{uuid=\\\"5e80926d-27b6-a1dc-cc4f-64f033face7f\\\"}\",\n",
    "        \"merge_fn\": gpu_mem_usage_merge_fn\n",
    "    },\n",
    "    \"gpu_power_draw\": {\n",
    "        \"query\": \"nvidia_smi_power_draw_watts{uuid=\\\"5e80926d-27b6-a1dc-cc4f-64f033face7f\\\"}\",\n",
    "        \"merge_fn\": gpu_power_draw_merge_fn\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_chunks = [\n",
    "    (\n",
    "        \"2025-02-26T20:30:00+01:00\",\n",
    "        \"2025-02-27T15:50:00+01:00\"\n",
    "    )\n",
    "]\n",
    "\n",
    "step = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_chunk in time_chunks:\n",
    "    chunk_start, chunk_end = time_chunk\n",
    "\n",
    "    start_parsed = datetime.datetime.fromisoformat(chunk_start)\n",
    "    end_parsed = datetime.datetime.fromisoformat(chunk_end)\n",
    "\n",
    "    start = start_parsed.timestamp()\n",
    "    end = end_parsed.timestamp()\n",
    "\n",
    "    for query_name, query_details in queries.items():\n",
    "        accumulator = {}\n",
    "        cursor = start\n",
    "\n",
    "        while cursor < end:\n",
    "            real_end = min(cursor + max_data_points, end)\n",
    "\n",
    "            params = {\n",
    "                \"query\": query_details[\"query\"],\n",
    "                \"start\": cursor,\n",
    "                \"end\": real_end,\n",
    "                \"step\": step\n",
    "            }\n",
    "\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response_json = response.json()\n",
    "\n",
    "            merge_fn = query_details[\"merge_fn\"]\n",
    "            merge_fn(accumulator, response_json)\n",
    "\n",
    "            cursor += max_data_points\n",
    "\n",
    "        with open(f\"{PERF_DIR}/{query_name}.json\", \"w\") as file:\n",
    "            json.dump(accumulator, file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
