{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "N_QUERIES = 500\n",
    "\n",
    "MODELS = [\"tgrm\", \"e5\", \"labse\", \"gte\"]\n",
    "UNITS = [\"page\", \"paragraph\", \"sentence\"]\n",
    "LANGUAGES = [\"en\", \"sk\", \"de\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[page]: 0.14\n",
      "[paragraph]: 0.2962963\n",
      "[sentence]: 0.3125\n"
     ]
    }
   ],
   "source": [
    "thresholds = {}\n",
    "\n",
    "for unit in UNITS:\n",
    "    docs = []\n",
    "\n",
    "    for lang in LANGUAGES:\n",
    "        for idx in range(N_QUERIES):\n",
    "            with open(f\"../../data/retrieval/tgrm/{unit}-{lang}-{idx + 1}.json\") as file:\n",
    "                retrieval = json.load(file)\n",
    "                documents = retrieval[\"documents\"]\n",
    "                docs.extend(documents)\n",
    "\n",
    "    docs = sorted(docs, key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    doc = docs[N * N_QUERIES * len(LANGUAGES) - 1]\n",
    "    t = doc[\"similarity\"]\n",
    "\n",
    "    print(f\"[{unit}]: {t}\")\n",
    "    thresholds[unit] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[page]: 5.04\n",
      "[paragraph]: 5.008666666666667\n",
      "[sentence]: 5.080666666666667\n"
     ]
    }
   ],
   "source": [
    "for unit in UNITS:\n",
    "    threshold = thresholds[unit]\n",
    "    ns = []\n",
    "\n",
    "    for lang in LANGUAGES:\n",
    "        for idx in range(N_QUERIES):\n",
    "            with open(f\"../../data/retrieval/tgrm/{unit}-{lang}-{idx + 1}.json\") as file:\n",
    "                retrieval = json.load(file)\n",
    "                documents = retrieval[\"documents\"]\n",
    "\n",
    "                n = 0\n",
    "                while n < len(documents):\n",
    "                    similarity = documents[n][\"similarity\"]\n",
    "\n",
    "                    if similarity < threshold:\n",
    "                        break\n",
    "\n",
    "                    n += 1\n",
    "\n",
    "                ns.append(n)\n",
    "\n",
    "    avg_n = sum(ns) / len(ns)\n",
    "    print(f\"[{unit}]: {avg_n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
